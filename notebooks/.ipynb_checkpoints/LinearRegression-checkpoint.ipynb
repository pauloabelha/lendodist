{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning from linear data (plus noise)\n",
    "\n",
    "Welcome to this notebook.\n",
    "\n",
    "I'm Paulo Abelha and this ntoebook is available at my GitHub http://ww.github.com/pauloabelha/notebooks\n",
    "\n",
    "I made this as part of my own studies in Machine Learning.\n",
    "\n",
    "The idea is start simple, but principled and work our way up the abstractions.\n",
    "\n",
    "Therefore we deal with the \"hello world\" of Machine Learning: Linear regression\n",
    "\n",
    "All code in here is of my own authorship.\n",
    "\n",
    "Main Resources:\n",
    "- Wikipedia\n",
    "- David Mackay's bible was a valuable resource: http://www.inference.org.uk/mackay/itila/book.html\n",
    "- This great paper: MacKay, David JC. \"Bayesian interpolation.\" Neural computation 4.3 (1992): 415-447.\n",
    "- Another great book: http://www.gaussianprocess.org/gpml/\n",
    "- Yet another great book: http://www.deeplearningbook.org/\n",
    "\n",
    "In this notebook we compare four different Machine Learning approaches for fitting a function to noisy linear data\n",
    "- Linear Regression\n",
    "- Bayesian Linear Regression\n",
    "- Neural Networks\n",
    "- Gaussian Processes\n",
    "\n",
    "\n",
    "p.s.: One interesting thing would be to implement our own Gaussian distribution sampler:\n",
    "\n",
    "    http://www.alanzucconi.com/2015/09/16/how-to-sample-from-a-gaussian-distribution/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "# for reproducibility\n",
    "random_seed_ix = 1\n",
    "np.random.seed(random_seed_ix)\n",
    "# number of data points\n",
    "n_pts = 100\n",
    "n_dims = 1\n",
    "# noise level (variance of Gaussian distribution for noise)\n",
    "noise_sigma = np.random.rand(random_seed_ix)*0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X is originally a matrix of (n_pts,n_dis), but we encode the bias by adding a column of ones to it the linear model becomes just\n",
    "# y = X*w isntead of y = X*w + b\n",
    "# We also add the bias to the weight vector\n",
    "def augment_with_bias(X,b,w):\n",
    "    n_pts = X.shape[0]\n",
    "    n_dims = X.shape[1]\n",
    "    X_b = np.hstack((X,np.ones((n_pts,1))))\n",
    "    w_b = np.append(w,np.full((1,1),b),axis=0)\n",
    "    return X_b, w_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decode data encoded by augment_with_bias to retrieve the original X, w matrices and the bias b\n",
    "def disaugment_with_bias(X_b,w_b):\n",
    "    X = X_b[:,:-1]\n",
    "    b = w_b[-1,0]\n",
    "    w = w_b[:-1,:]\n",
    "    return X, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot a cooolwarm surface given an m x n matrix Z with values\n",
    "def my_plot_3Dsurf(range_x,range_y,Z,label_x = 'x',label_y = 'y', viewpoint = 111, fontsize_x = 18, fontsize_y = 18):\n",
    "    x = np.linspace(range_x[0], range_x[1], Z.shape[0])\n",
    "    y = np.linspace(range_y[0], range_y[1], Z.shape[1])\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(viewpoint, projection='3d')\n",
    "    ax.plot_surface(xv, yv, Z, cmap=cm.coolwarm)\n",
    "    plt.xlabel(label_x, fontsize=fontsize_x)\n",
    "    plt.ylabel(label_y, fontsize=fontsize_y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_plot_birdview(Z):\n",
    "    plt.imshow(np.reshape(Z, (Z.shape[0],-1)), origin='lower', extent=[0,1,0,1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1 - Linear Model for Generating Data**\n",
    "\n",
    "Here we:\n",
    "- Define our linear model plus noise\n",
    "- Define the function for generating the data\n",
    "- Plot the data and information about it (matrices' shapes and value for the weight w and bias b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the linear model y = X*w + b using the encoded bias\n",
    "def linear_model(X,w,noise_sigma = 0):\n",
    "    n_pts = X.shape[0]\n",
    "    X_b, w_b = augment_with_bias(X,b,w)\n",
    "    noise_vec = np.random.normal(0,noise_sigma,(n_pts,1))    \n",
    "    y = np.dot(X_b,w_b) + noise_vec\n",
    "    # ensure y is a (n_pts,1) vector\n",
    "    assert(y.shape[0] == n_pts)\n",
    "    assert(y.shape[1] == 1)\n",
    "    return y, noise_vec, X_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate Gaussian-noisy linear data plus\n",
    "# X is (n_pts,n_dims), where n is number of examples and d is numebr of dimensions\n",
    "# the bias is included in X as an extra column\n",
    "# so the vector w also gets an extra element (always 1)\n",
    "# y is (n_pts,1)\n",
    "# currently this code is for one dimension only\n",
    "def gen_Gauss_noisy_lin_data(n_pts, noise_sigma, random_seed_ix = 1, plot_fig = 0):  \n",
    "    # number of dimensions\n",
    "    n_dims = 1\n",
    "    # for reproducibility\n",
    "    np.random.seed(random_seed_ix)    \n",
    "    # get X as a random matrix (with one xtra column for adding bias)\n",
    "    X = np.random.rand(n_pts,n_dims)\n",
    "    # add the bias by overwriting the extra column of X\n",
    "    b = np.random.rand()\n",
    "    # ensure w has only positive values (for more intuitive visualisation from left to right)\n",
    "    w_1 = abs(np.random.rand(n_dims,1))\n",
    "    # get full weight vector\n",
    "    w = np.zeros((2,1))\n",
    "    w[0,0] = w_1\n",
    "    w[1,0] = b\n",
    "    # get y\n",
    "    y, noise_vec, X_b = linear_model(X,w,noise_sigma)\n",
    "    if plot_fig:\n",
    "        plt.scatter(X, y, color='k')\n",
    "        plt.show()\n",
    "    return (X_b, y, w_b, noise_vec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'X_b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-d1bc676a49ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot the data and information about it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_Gauss_noisy_lin_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_pts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise_sigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_seed_ix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_train shape (wth added bias) = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y_train shape = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"w shape (with added bias) = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-e97406f9d72d>\u001b[0m in \u001b[0;36mgen_Gauss_noisy_lin_data\u001b[0;34m(n_pts, noise_sigma, random_seed_ix, plot_fig)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# get y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise_sigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mplot_fig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-e352989528dd>\u001b[0m in \u001b[0;36mlinear_model\u001b[0;34m(X, w, noise_sigma)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#X_b, w_b = augment_with_bias(X,b,w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnoise_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise_sigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_pts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise_vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# ensure y is a (n_pts,1) vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_pts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'X_b' is not defined"
     ]
    }
   ],
   "source": [
    "# plot the data and information about it\n",
    "X_train_b, y_train, w_b, noise = gen_Gauss_noisy_lin_data(n_pts,noise_sigma,random_seed_ix,True)\n",
    "print(\"X_train shape (wth added bias) = \" + str(X_train_b.shape))\n",
    "print(\"y_train shape = \" + str(y_train.shape))\n",
    "print(\"w shape (with added bias) = \" + str(w_b.shape))\n",
    "print(\"noise shape = \" + str(noise.shape))\n",
    "print(\"w = \" + str(w_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 - Linear Regresion**\n",
    "\n",
    "Here we:\n",
    "- Define our loss function as mean squared errors\n",
    "- Perform Linear Regresion on the generated data\n",
    "- Plot the fit in data space\n",
    "- Plot the loss function in parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean squared error for our linear model\n",
    "def my_mse(y_hat,y):\n",
    "    m = y_hat.shape[1]\n",
    "    mse = (1/m)*np.sum(np.power(y_hat-y,2))\n",
    "    return mse    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform linear regression using mean squared error as loss function\n",
    "# please, do go through the derivations in: http://www.deeplearningbook.org/contents/ml.html (Section 5.1.4)\n",
    "def my_linear_regression(X_train,y_train):\n",
    "    assert(X_train.shape[0] == y_train.shape[0])\n",
    "    # separate the derivation into chunks for easier understanding\n",
    "    a = np.linalg.inv(np.dot(X_train.T,X_train))\n",
    "    b = np.dot(a,X_train.T)\n",
    "    w_pred = np.dot(b,y_train) \n",
    "    # get predictions\n",
    "    y_pred = np.dot(X_train,w_pred)\n",
    "    assert(y_pred.shape == y_train.shape)\n",
    "    # get mean squared error\n",
    "    mse = my_mse(y_train,y_pred)\n",
    "    return w_pred, y_pred, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted w = [[ 0.52575045]]\n",
      "Real w = [[ 0.5270581]]\n",
      "Predicted b = 0.326644901772\n",
      "Real b = 0.32934678169\n",
      "Mean squared error = 0.0332110310993\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe686742dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# call linear regression on our training data and get the real and predicted values for w and b, plotting the fit\n",
    "w_pred, y_pred, mse = my_linear_regression(X_train_b,y_train)\n",
    "X_train, w, b = disaugment_with_bias(X_train_b,w_b)\n",
    "print(\"Predicted w = \" + str(w_pred[:-1,:]))\n",
    "print(\"Real w = \" + str(w))\n",
    "print(\"Predicted b = \" + str(b))\n",
    "print(\"Real b = \" + str(w_pred[1,0]))\n",
    "print(\"Mean squared error = \" + str(mse))\n",
    "\n",
    "plt.plot(X_train,y_pred, color = 'r')\n",
    "plt.scatter(X_train, y_train, color = 'k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-fc116d992a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m          \u001b[0;31m# force float by multiplying by 1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mw_curr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_curr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_curr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mmse_errors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmse_errors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_mse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-1f0eaeda1616>\u001b[0m in \u001b[0;36mlinear_model\u001b[0;34m(X, w, b, noise_sigma)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise_sigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mn_pts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mX_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment_with_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mnoise_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise_sigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_pts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnoise_vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-66945106dddf>\u001b[0m in \u001b[0;36maugment_with_bias\u001b[0;34m(X, b, w)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mn_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_pts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mw_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5145\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5146\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5147\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "# get the mean squared errors for a range of w and b values and plot the error surface\n",
    "n_iter = 100\n",
    "w_curr = np.zeros((2,1))\n",
    "mse_errors = np.zeros((n_iter,n_iter))\n",
    "min_mse = np.Inf\n",
    "for i in range(n_iter):\n",
    "    # force float by multiplying by 1.0\n",
    "    w_curr[0,0] = 1.0*i/n_iter\n",
    "    for j in range(n_iter):\n",
    "         # force float by multiplying by 1.0\n",
    "        w_curr[1,0] = 1.0*j/n_iter\n",
    "        y_hat, _, _, _ = linear_model(X_train,w_curr[0,0],w_curr[1,0])\n",
    "        mse_errors[i,j] = my_mse(y_hat,y_train)\n",
    "        if mse_errors[i,j] < min_mse:\n",
    "            min_mse = mse_errors[i,j]\n",
    "            min_w = np.array(w_curr, copy = True)\n",
    "#my_plot_3Dsurf([0, 1],[0, 1],mse_errors,'b','w')\n",
    "print(\"Minimum mean squared error = \" + str(max_P) + \" at (\" + str(best_w[0,0]) + \",\" + str(best_w[1,0]) + \")\")\n",
    "my_plot_birdview(mse_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that we were able to estimate quite closely the global minimum, but we don't have error bars nor any sort of probability distribution over the parameters\n",
    "Try removing the noise form the linear model to see what happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**1.2 Bayesian linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Following notation in [2], but in our case, we do not have fixed basis functions $\\phi_h(x)$\n",
       "$$ \\mathbf{y} = \\mathbf{X} \\mathbf{w} + v_m $$\n",
       "$$ v_m \\sim N(0,\\sigma_v) $$\n",
       "$$ D = (\\mathbf{X}_i,\\mathbf{y}_i) $$\n",
       "$$ P(D|\\mathbf{w},\\sigma_v) =  N(X_i \\mathbf{w},\\sigma_v) $$\n",
       "$$ P(D|\\mathbf{w},\\sigma_v) = \\prod_{i=1}^{N} N(X_i \\mathbf{w},\\sigma_v) = \\frac{exp[-\\beta E_D(\\mathbf{y}|\\mathbf{w})]}{Z_D} $$ \n",
       "$$ Z_D = \\Big(\\frac{2\\pi}{\\beta}\\Big)^\\frac{N}{2} $$\n",
       "$$ \\beta = \\frac{1}{\\sigma_v^2} $$\n",
       "$$ E_D = \\sum_{i}^N (\\mathbf{X}_i\\mathbf{w}-\\mathbf{y}_i)^2  $$\n",
       "$E_D$ is the squared difference between the model with ($\\mathbf{y}_i$) and without ($\\mathbf{X}_i\\mathbf{w}$) noise\n",
       "$$$$\n",
       "$P(D|\\mathbf{w},\\sigma_v)$ is the likelihood of the parameters given the data"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "Following notation in [2], but in our case, we do not have fixed basis functions $\\phi_h(x)$\n",
    "$$ \\mathbf{y} = \\mathbf{X} \\mathbf{w} + v_m $$\n",
    "$$ v_m \\sim N(0,\\sigma_v) $$\n",
    "$$ D = (\\mathbf{X}_i,\\mathbf{y}_i) $$\n",
    "$$ P(D|\\mathbf{w},\\sigma_v) =  N(X_i \\mathbf{w},\\sigma_v) $$\n",
    "$$ P(D|\\mathbf{w},\\sigma_v) = \\prod_{i=1}^{N} N(X_i \\mathbf{w},\\sigma_v) = \\frac{exp[-\\beta E_D(\\mathbf{y}|\\mathbf{w})]}{Z_D} $$ \n",
    "$$ Z_D = \\Big(\\frac{2\\pi}{\\beta}\\Big)^\\frac{N}{2} $$\n",
    "$$ \\beta = \\frac{1}{\\sigma_v^2} $$\n",
    "$$ E_D = \\sum_{i}^N (\\mathbf{X}_i\\mathbf{w}-\\mathbf{y}_i)^2  $$\n",
    "$E_D$ is the squared difference between the model with ($\\mathbf{y}_i$) and without ($\\mathbf{X}_i\\mathbf{w}$) noise\n",
    "$$$$\n",
    "$P(D|\\mathbf{w},\\sigma_v)$ is the likelihood of the parameters given the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_linear_model(n_pts, w, noise_sigma):\n",
    "    X_b, y, _, _ = gen_Gauss_noisy_lin_data(n_pts,noise_sigma)\n",
    "    beta = np.power(1.0/noise_sigma,2)\n",
    "    Z_D = np.power((2.0*np.pi/beta),n_pts/2)\n",
    "    E_D = (1.0/2)*np.sum(np.power((y - np.dot(X_b,w)),2))\n",
    "    P = np.exp(-beta*E_D)\n",
    "    return P, X_b, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max likelihood = 1.09783410018e-17 at (0.52,0.33)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwzBIahgGSQ3DIKlhGCQ1DIOkhmGQ1Pgf7FlRt3w4Vf4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe686555a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_iter = 100\n",
    "w_curr = np.zeros((n_dims+1,1))\n",
    "best_w = np.zeros((n_dims+1,1))\n",
    "Ps = np.zeros((n_iter,n_iter))\n",
    "max_P = -1\n",
    "for i in range(n_iter):\n",
    "    w_curr[0,0] = 1.0*i/n_iter\n",
    "    for j in range(n_iter):\n",
    "        w_curr[1,0] = 1.0*j/n_iter\n",
    "        Ps[i,j], _, _ = likelihood_linear_model(n_pts,w_curr,noise_sigma)\n",
    "        if Ps[i,j] > max_P:\n",
    "            max_P = Ps[i,j]            \n",
    "            best_w = np.array(w_curr, copy=True)\n",
    "print(\"Max likelihood = \" + str(max_P) + \" at (\" + str(best_w[0,0]) + \",\" + str(best_w[1,0]) + \")\")\n",
    "#my_plot_3Dsurf([0, 1],[0, 1],Ps,'b','w')\n",
    "my_plot_birdview(Ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] MacKay, David JC. Information theory, inference and learning algorithms. Cambridge university press, 2003.\n",
    "\n",
    "[2] MacKay, David JC. \"Bayesian interpolation.\" Neural computation 4.3 (1992): 415-447."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
